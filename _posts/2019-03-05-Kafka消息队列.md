---
layout: post
title: "Kafka消息队列"
date: 2019-03-05
description: ""
tag: 大数据
---
### Kafka是什么

Apache Kafka是一个快速、可扩展的、高吞吐的、可容错的分布式“发布-订阅”消息系统， 使用 Scala与Java语言编写，能够将消息从一个端点传递到另一个端点。

### 主要设计目标

-  以时间复杂度为O(1)的方式提供消息持久化能力，保证对TB级以上的数据也能保证常数时间的访问性能。

- 支持Kfk Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输。

- 同时支持离线数据处理和实时数据处理。

- 支持在线水平扩展

### Kafka的应用场景

1. **用户的活动跟踪：**用户在网站的不同活动消息发布到不同的主题中心，然后可以对这些消息进行实时监测、实时处理。也可以加载到 Hadoop或离线处理数据仓库，对用户进行画像。像淘宝、天猫、京东这些大型电商平台，用户的所有活动都要进行追踪的。

2. **日志收集：**日志采集客户端收集日志，将其写入Kafka消息队列，然后日志处理应用在Kafka消息队列订阅消息。

3. **限流削峰：**用户请求写入消息队列，秒杀业务处理根据规则读取秒杀请求读取消息队列。

4. **高吞吐率实现：**高吞吐是kfk消息队列的特点，为了增加存储能力，kfk将所有的消息写入到低速大容量的硬盘中。

   实现高吞吐率的有如下几点：

   ​	**顺序读写：**Kfk将消息写入到分区Partition中，而分区中的消息又是顺序读写的，顺序读写要快于随机读写

   ​	**零拷贝：**生产者、消费者对于Kafka中的消息是采用零拷贝实现的。

   ​	**批量发送：**Kafka允许批量发送模式。

   ​	**消息压缩：**Kfk允许对消息集合进行压缩。

### Kafka优点

|        优点         |                             解释                             |
| :-----------------: | :----------------------------------------------------------: |
|        解耦         | 消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。 |
|     冗余(副本)      | 消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存，直到你使用完毕。 |
|       扩展性        | 因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。 |
| 灵活性&峰值处理能力 | 在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。 |
|      可恢复性       | 系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。 |
|      顺序保证       | 在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka 保证一个 Partition 内的消息的有序性。 |
|        缓冲         | 在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行，写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。 |
|      异步通信       | 很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。 |

### Kafka与Flume比较

Kafka：适合数据下游消费众多的情况；适合数据安全性要求较高的操作，支持 replication。

Flume：适合多个生产者；适合下游数据消费者不多的情况；适合数据安全性要求不高的操作；适合与 Hadoop 生态圈对接的操作。

常用的一种模型：线上数据 --> flume --> kafka --> flume(根据情景增删该流程) --> HDFS

### kafka充当的重要角色

**1、Kafka 作为存储系统：**任何允许发布与使用无关的消息发布的消息队列都有效地充当了运行中消息的存储系统。Kafka 的不同之处在于它是一个非常好的存储系统。写入 Kafka 的数据将写入磁盘并进行复制以实现容错功能。Kafka 允许生产者等待确认，以便直到完全复制并确保即使写入服务器失败的情况下写入也不会完成。Kafka 的磁盘结构可以很好地扩展使用-无论服务器上有 50KB 还是 50TB 的持久数据，Kafka 都将执行相同的操作。由于认真对待存储并允许客户端控制其读取位置，因此您可以将 Kafka 视为一种专用于高性能，低延迟提交日志存储，复制和传播的专用分布式文件系统。

**2、Kafka 作为消息传递系统：**消息传递具有两种模型：排队和发布订阅。在队列中，一组使用者可以从服务器中读取内容，并且每条记录都将转到其中一个。在发布-订阅记录中广播给所有消费者。这两个模型中的每一个都有优点和缺点。排队的优势：它允许您将数据处理划分到多个使用者实例上，从而扩展处理量。缺点：队列不是多用户的一一次进程读取了丢失的数据。而发布-订阅的优点：允许您将数据广播到多个进程，但是由于每条消息都传递给每个订阅者，缺点：无法扩展处理。Kafka 的消费者群体概念概括了这两个概念。与队列一样，使用者组允许您将处理划分为一组进程（使用者组的成员）。与发布订阅一样，Kafka允许您将消息广播到多个消费者组。Kafka 模型的优点在于，每个主题都具有这些属性-可以扩展处理范围，并且是多订阅者，无需选择其中一个。与传统的消息传递系统相比，Kafka 还具有更强的订购保证。传统队列将记录按顺序保留在服务器上，如果多个使用者从队列中消费，则服务器将按记录的存储顺序分发记录。但是，尽管服务器按顺序分发记录，但是这些记录是异步传递给使用者的，因此它们可能在不同的使用者上乱序到达。这实际上意味着在并行使用的情况下会丢失记录的顺序。消息传递系统通常通过“专有使用者”的概念来解决此问题，该概念仅允许一个进程从队列中使用，但是，这当然意味着在处理中没有并行性。Kafka 做得更好，通过在主题内具有并行性（即分区）的概念，Kafka 能够在用户进程池中提供排序保证和负载均衡。这是通过将主题中的分区分配给消费者组中的消费者来实现的，以便每个分区都由组中的一个消费者完全消费。通过这样做，我们确保使用者是该分区的唯一读取器，并按顺序使用数据。由于存在许多分区，因此仍然可以平衡许多使用者实例上的负载。但是请注意，使用者组中的使用者实例不能超过分区。

**Kafka 用作流处理：**仅读取，写入和存储数据流是不够的，目的是实现对流的实时处理。在 Kafka 中，流处理器是指从输入主题中获取连续数据流，对该输入进行一些处理并生成连续数据流以输出主题的任何东西。例如，零售应用程序可以接受销售和装运的输入流，并输出根据此数据计算出的重新订购和价格调整流。可以直接使用生产者和消费者 API 进行简单处理。但是，对于更复杂的转换，Kafka 提供了完全集成的 Streams API。这允许构建执行非重要处理的应用程序，这些应用程序计算流的聚合或将流连接在一起。该功能有助于解决此类应用程序所面临的难题：处理无序数据，在代码更改时重新处理输入，执行状态计算等。流 API 建立在 Kafka 提供的核心原语之上：它使用生产者和使用者 API 进行输入，使用 Kafka 进行状态存储，并使用相同的组机制来实现流处理器实例之间的容错。

**为什么当下有这么多的主流流式处理系统还要有kfk Stream？**

- 第一，Spark和Storm都是流式处理框架，而 Kafka Stream 提供的是一个基于Kafka的流式处理类库。框架要求开发者按照特定的方式去开发逻辑部分，供框架调用。开发者很难了解框架的具体运行方式，从而使得调试成本高，并且使用受限。而 Kafka Stream 作为流式处理类库，直接提供具体的类给开发者调用，整个应用的运行方式主要由开发者控制，方便使用和调试。
- 第二，虽然 Cloudera 与 Hortonworks 方便了 Storm 和 Spark 的部署，但是这些框架的部署仍然相对复杂。而 Kafka Stream 作为类库，可以非常方便的嵌入应用程序中，它对应用的打包和部署基本没有任何要求。
- 第三，就流式处理系统而言，基本都支持 Kafka 作为数据源。例如 Storm 具有专门的kafka-spout，而 Spark 也提供专门的 spark-streaming-kafka 模块。事实上，Kafka 基本上是主流的流式处理系统的标准数据源。换言之，大部分流式系统中都已部署了 Kafka，此时使用Kafka Stream 的成本非常低。
- 第四，使用 Storm 或 Spark Streaming 时，需要为框架本身的进程预留资源，如 Storm的 supervisor 和 Spark on YARN 的 node manager。但是 Kafka 作为类库不占用系统资源。
- 第五，由于 Kafka 本身提供数据持久化，因此 Kafka Stream 提供滚动部署和滚动升级以及重新计算的能力。
- 第六，由于 Kafka Consumer Rebalance 机制，Kafka Stream 可以在线动态调整并行度。

### Kafka架构体系如图

<img src="/images/posts/kfk/kfk架构图.jpg"  />

**`Topic`：主题。**是一堆或者一组消息，Topic 相当于消息的分类标签，是一个逻辑概念。物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个Broker上但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处。

**`Partition`：分区。**Topic中的消息被分割为一个或多个Partition，其是一个物理概念，对应到系统上就是一个或若干个目录。Partition 内部的消息是有序的，但 Partition 间的消息是无序的。

**`Segment`: 段。**将Partition进一步细分为了若干的Segment，每个Segment文件的大小相等。

**`Broker`：经纪人**。Kafka集群包含一个或多个服务器，每个服务器节点称为一个Broker。Broker 存储 Topic 的数据。

如果某 Topic 有 N 个Partition，集群有 N 个Broker，那么每个Broker存储该Topic 的一个Partition。如果某Topic有N 个Partition，集群有（N+M）个 Broker，那么其中有N个 Broker存储该Topic的一个Partition，剩下的M个 Broker不存储该Topic的Partition数据。如果某Topic 有N个Partition，集群中Broker数目少于N个，那么一个 Broker存储该Topic的一个或多个Partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致 Kafka集群数据不均衡。

**`Producer`：生产者。**即消息的发布者，生产者将数据发布到他们选择的主题。生产者负责选择将哪个记录分配给主题中的哪个分区。即：生产者生产的一条消息，会被写入到某一个Partition。

**`Consumer`：消费者。**可以从Broker中读取消息。一个消费者可以消费多个Topic的消息；一个消费者可以消费同一个 Topic 中的多个Partition中的消息；一个Partiton允许多个Consumer 同时消费。

**`Consumer Group`：消费者组**。Consumer Group 是Kafka提供的可扩展且具有容错性的消费者机制。组内可以有多个消费者，它们共享一个公共的ID，即Group ID。组内的所有消费者协调在一起来消费订阅主题 的所有分区。Kafka保证同一个Consumer Group 中只有一个Consumer会消费某条消息。实际上，Kafka保证的是稳定状态下每一个 Consumer 实例只会消费某一个或多个特定的Partition，而某个Partition 的数据只会被某一个特定的Consumer 实例所消费。

**Replizcas of partition：分区副本。**副本是一个分区的备份，是为了防止消息丢失而创建的分区的备份。

**Partition Leader：**每个Partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责消息读写 的 Partition。即所有读写操作只能发生于Leader分区上。

**Partition Follower：**所有Follower都需要从Leader同步消息，Follower与 Leader始终保持消息同步。Leader 与Follower的关系是主备关系，而非主从关系。

**ISR：**

- **ISR，In-Sync Replicas，**是指副本同步列表。ISR列表是由Leader负责维护。
- **AR，Assigned Replicas，**指某个Partition的所有副本, 即已分配的副本列表。
- **OSR，Outof-Sync Replicas，**即非同步的副本列表。
- **AR=ISR+OSR**

**Offset：偏移量。**每条消息都有一个当前Partition下唯一的 64 字节的Offset，给分区中的消息提供一个顺序ID号，为了唯一地识别分区中的每条消息。

**Broker Controller：**Kafka集群的多个 Broker 中，有一个会被选举Controller，负责管理整个集群中 Partition 和 Replicas 的状态。只有 Broker Controller 会向 Zookeeper 中注册 Watcher，其他 Broker 及分区无需注册。即 Zookeeper 仅需监听 Broker Controller 的状态变化即可。

**HW 与 LEO：**

- **HW，HighWatermark，**高水位，表示 Consumer 可以消费到的最高 Partition偏移量。HW 保证了Kafka集群中消息的一致性。确切地说，是保证了Partition的Follower与Leader间数 据的一致性。
- **LEO，Log End Offset，**日志最后消息的偏移量。消息是被写入到 Kafka 的日志文件中的， 这是当前最后一个写入的消息在Partition中的偏移量。
- 对于Leader新写入的消息，Consumer是不能立刻消费的。Leader会等待该消息被所有 ISR中的Partition Follower同步后才会更新HW，此时消息才能被Consumer消费。

**Zookeeper：**Zookeeper 负责维护和协调 Broker，负责 Broker Controller 的选举。在 Kafka 0.9 之前版本，Offset 是由 ZK 负责管理的。

**总结：**ZK 负责 Controller 的选举，Controller 负责 Leader 的选举。

**Coordinator：**一般指的是运行在每个 Broker 上的 Group Coordinator 进程，用于管理 Consumer Group 中的各个成员，主要用于 Offset 位移管理和 Rebalance。一个 Coordinator 可以同时管理多个消费者组。

**Rebalance：**当消费者组中的数量发生变化，或者 Topic 中的 Partition 数量发生了变化时，Partition 的所有权会在消费者间转移，即 Partition 会重新分配，这个过程称为再均衡 Rebalance。再均衡能够给消费者组及 Broker 带来高性能、高可用性和伸缩，但在再均衡期间消费者是无法读取消息的，即整个 Broker 集群有小一段时间是不可用的。因此要避免不必要的再均衡。

**Offset Commit：**Consumer 从 Broker 中取一批消息写入 Buffer 进行消费，在规定的时间内消费完消息后，会自动将其消费消息的 Offset 提交给 Broker，以记录下哪些消息是消费过的。当然，若在时限内没有消费完毕，其是不会提交 Offset 的。

### kafka的工作原理和过程：

**①消息写入算法**

消息发送者将消息发送给 Broker, 并形成最终的可供消费者消费的 log，是已给比较复杂的过程：

- Producer 先从 Zookeeper 中找到该 Partition 的 Leader。
- Producer将消息发送给该 Leader。
- Leader 将消息接入本地的 log，并通知 ISR 的 Followers。
- ISR 中的 Followers 从 Leader 中 Pull 消息, 写入本地 log 后向 Leader 发送 Ack。
- Leader 收到所有 ISR 中的 Followers 的 Ack 后，增加 HW 并向 Producer 发送 Ack，表示消息写入成功。

**②消息路由策略**

在通过 API 方式发布消息时，生产者是以 Record 为消息进行发布的。Record 中包含 Key 与 Value，Value 才是我们真正的消息本身，而 Key 用于路由消息所要存放的 Partition。消息要写入到哪个 Partition 并不是随机的，而是有路由策略的：

- 若指定了 Partition，则直接写入到指定的 Partition。
- 若未指定 Partition 但指定了 Key，则通过对 Key 的 Hash 值与 Partition 数量取模，该取模。
- 结果就是要选出的 Partition 索引。
- 若 Partition 和 Key 都未指定，则使用轮询算法选出一个 Partition。

**③HW 截断机制**

如果 Partition Leader 接收到了新的消息， ISR 中其它 Follower 正在同步过程中，还未同步完毕时 leader 宕机。此时就需要选举出新的 Leader。若没有 HW 截断机制，将会导致 Partition 中 Leader 与 Follower 数据的不一致。当原 Leader 宕机后又恢复时，将其 LEO 回退到其宕机时的 HW，然后再与新的 Leader 进行数据同步，这样就可以保证老 Leader 与新 Leader 中数据一致了，这种机制称为 HW 截断机制。

**④消息发送的可靠性**

生产者向 Kafka 发送消息时，可以选择需要的可靠性级别。通过 request.required.acks 参数的值进行设置。

**0 值：异步发送。**生产者向 Kafka 发送消息而不需要 Kafka 反馈成功 Ack。该方式效率最高，但可靠性最低。

其可能会存在消息丢失的情况：

- 在传输过程中会出现消息丢失。
- 在 Broker 内部会出现消息丢失。
- 会出现写入到 Kafka 中的消息的顺序与生产顺序不一致的情况。

**1 值：同步发送。**生产者发送消息给 Kafka，Broker 的 Partition Leader 在收到消息后马上发送成功 Ack（无需等等 ISR 中的 Follower 同步）。

生产者收到后知道消息发送成功，然后会再发送消息。如果一直未收到 Kafka 的 Ack，则生产者会认为消息发送失败，会重发消息。该方式对于 Producer 来说，若没有收到 Ack，一定可以确认消息发送失败了，然后可以重发。但是，即使收到了 ACK，也不能保证消息一定就发送成功了。故，这种情况，也可能会发生消息丢失的情况。

**-1 值：同步发送。**生产者发送消息给 Kafka，Kafka 收到消息后要等到 ISR 列表中的所有副本都 同步消息完成后，才向生产者发送成功 Ack。如果一直未收到 Kafka 的 Ack，则认为消息发送 失败，会自动重发消息。该方式会出现消息重复接收的情况。

**⑤消费者消费过程解析**

生产者将消息发送到 Topitc 中，消费者即可对其进行消费，其消费过程如下：

- Consumer 向 Broker 提交连接请求，其所连接上的 Broker 都会向其发送Broker Controller 的通信 URL，即配置文件中的 Listeners 地址。
- 当 Consumer 指定了要消费的 Topic 后，会向 Broker Controller 发送消费请求。
- Broker Controller 会为 Consumer 分配一个或几个 Partition Leader，并将该 Partition 的当前 Offset 发送给 Consumer。
- Consumer 会按照 Broker Controller 分配的 Partition 对其中的消息进行消费。
- 当 Consumer 消费完该条消息后，Consumer 会向 Broker 发送一个消息已经被消费反馈，即该消息的 Offset。
- 在 Broker 接收到 Consumer 的 Offset 后，会更新相应的 __consumer_offset 中。
- 以上过程会一直重复，知道消费者停止请求消费。
- Consumer 可以重置 Offset，从而可以灵活消费存储在 Broker 上的消息。

**⑥Partition Leader 选举范围**

当 Leader 宕机后，Broker Controller 会从 ISR 中挑选一个 Follower 成为新的 Leader。如果 ISR 中没有其他副本怎么办？可以通过 unclean.leader.election.enable 的值来设置 Leader 选举范围。

**False：**必须等到 ISR 列表中所有的副本都活过来才进行新的选举。该策略可靠性有保证，但可用性低。

**True：**在 ISR 列表中没有副本的情况下，可以选择任意一个没有宕机的主机作为新的 Leader，该策略可用性高，但可靠性没有保证。

**⑦重复消费问题的解决方案**

**同一个 Consumer 重复消费：**当 Consumer 由于消费能力低而引发了消费超时，则可能会形成重复消费。在某数据刚好消费完毕，但是正准备提交 Offset 时候，消费时间超时，则 Broker 认为这条消息未消费成功。这时就会产生重复消费问题。其解决方案：延长 Offset 提交时间。

**不同的 Consumer 重复消费：**当 Consumer 消费了消息，但还没有提交 Offset 时宕机，则这些已经被消费过的消息会被重复消费。其解决方案：将自动提交改为手动提交。

**⑧从架构设计上解决 Kafka 重复消费的问题**

我们在设计程序的时候，比如考虑到网络故障等一些异常的情况，我们都会设置消息的重试次数，可能还有其他可能出现消息重复，那我们应该如何解决呢？下面提供三个方案：

**方案一：保存并查询**

给每个消息都设置一个独一无二的 uuid，所有的消息，我们都要存一个 uuid。我们在消费消息的时候，首先去持久化系统中查询一下看这个看是否以前消费过，如没有消费过，在进行消费，如果已经消费过，丢弃就好了。

**方案二：利用幂等**

幂等（Idempotence）在数学上是这样定义的，如果一个函数 f(x) 满足：f(f(x)) = f(x)，则函数 f(x) 满足幂等性。这个概念被拓展到计算机领域，被用来描述一个操作、方法或者服务。一个幂等操作的特点是，其任意多次执行所产生的影响均与一次执行的影响相同。一个幂等的方法，使用同样的参数，对它进行多次调用和一次调用，对系统产生的影响是一样的。所以，对于幂等的方法，不用担心重复执行会对系统造成任何改变。

我们举个例子来说明一下。在不考虑并发的情况下，“将 X 老师的账户余额设置为 100 万元”，执行一次后对系统的影响是，X 老师的账户余额变成了 100 万元。

只要提供的参数 100 万元不变，那即使再执行多少次，X 老师的账户余额始终都是 100 万元，不会变化，这个操作就是一个幂等的操作。

再举一个例子，“将 X 老师的余额加 100 万元”，这个操作它就不是幂等的，每执行一次，账户余额就会增加 100 万元，执行多次和执行一次对系统的影响（也就是账户的余额）是不一样的。

所以，通过这两个例子，我们可以想到如果系统消费消息的业务逻辑具备幂等性，那就不用担心消息重复的问题了，因为同一条消息，消费一次和消费多次对系统的影响是完全一样的。也就可以认为，消费多次等于消费一次。

那么，如何实现幂等操作呢？最好的方式就是，从业务逻辑设计上入手，将消费的业务逻辑设计成具备幂等性的操作。但是，不是所有的业务都能设计成天然幂等的，这里就需要一些方法和技巧来实现幂等。常用的方法：利用数据库的唯一约束实现幂等。

**方案三：设置前提条件**

为更新的数据设置前置条件另外一种实现幂等的思路是，给数据变更设置一个前置条件，如果满足条件就更新数据，否则拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。

这样，重复执行这个操作时，由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。比如，刚刚我们说过，“将 X 老师的账户的余额增加 100 万元”这个操作并不满足幂等性，我们可以把这个操作加上一个前置条件，变为：“如果 X 老师的账户当前的余额为 500 万元，将余额加 100 万元”，这个操作就具备了幂等性。对应到消息队列中的使用时，可以在发消息时在消息体中带上当前的余额，在消费的时候进行判断数据库中，当前余额是否与消息中的余额相等，只有相等才执行变更操作。

### kafka producer拦截器(interceptor)

**原理：**Producer 拦截器(interceptor)主要用于实现 clients 端的定制化控制逻辑。对于producer而言，interceptor使得用户在消息发送前以及 producer 回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，producer允许用户指定多个 interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。Intercetpor 的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括：

(1) configure(configs)：获取配置信息和初始化数据时调用。

(2) onSend(ProducerRecord)：该方法封装进 KafkaProducer.send 方法中，即它运行在用户主线程中。Producer 确保在消息被序列化以及计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好

保证不要修改消息所属的 topic 和分区，否则会影响目标分区的计算

(3) onAcknowledgement(RecordMetadata, Exception)：该方法会在消息被应答或消息发送失败时调用，并且通常都是在 producer 回调逻辑触发之前。onAcknowledgement 运行在 producer 的 IO 线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢 producer 的消息发送效率

(4 )close：关闭 interceptor，主要用于执行一些资源清理工作,如前所述，interceptor 可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外倘若指定了多个 interceptor，则 producer 将按照指定顺序调用它们，并仅仅是捕获每个 interceptor 可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。

**案例:**需求：实现一个简单的双 interceptor 组成的拦截链。第一个 interceptor 会在消息发送前将时间戳信息加到消息 value 的最前部；第二个 interceptor会在消息发送后更新成功发送消息数或失败发送消息数。

**实操：**
1、增加时间戳拦截器

```java
package com.atguigu.kafka.interceptor;
import java.util.Map;
import org.apache.kafka.clients.producer.ProducerInterceptor;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
public class TimeInterceptor implements ProducerInterceptor<String, String> {
@Override
public void configure(Map<String, ?> configs) {
}

@Override
    public ProducerRecord<String, String> onSend(ProducerRecord<String, String>
record) {
    // 创建一个新的 record，把时间戳写入消息体的最前部
    return new ProducerRecord(record.topic(), record.partition(),
    record.timestamp(), record.key(),
    System.currentTimeMillis() + "," + record.value().toString());
    	}

@Override
public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
	}

@Override
public void close() {
	}
}
```

2、统计发送消息成功和发送失败消息数，并在 producer 关闭时打印这两个计数器

```java
package com.atguigu.kafka.interceptor;
import java.util.Map;
import org.apache.kafka.clients.producer.ProducerInterceptor;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
public class CounterInterceptor implements ProducerInterceptor<String, String>{
 	private int errorCounter = 0;
 	private int successCounter = 0;

@Override
public void configure(Map<String, ?> configs) {
	}

@Override
public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {
	return record;
	}

@Override
public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
	 // 统计成功和失败的次数
     if (exception == null) {
     successCounter++;
     } else {
     errorCounter++;
     }
	}

@Override
public void close() {
     // 保存结果
     System.out.println("Successful sent: " + successCounter);
     System.out.println("Failed sent: " + errorCounter);
	}
}
```

3、producer主程序

```java
package com.atguigu.kafka.interceptor;
import java.util.ArrayList;
import java.util.List;
import java.util.Properties;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
public class InterceptorProducer {
    public static void main(String[] args) throws Exception {
        // 1 设置配置信息
        Properties props = new Properties();
        props.put("bootstrap.servers", "hadoop102:9092");
        props.put("acks", "all");
        props.put("retries", 0);
        props.put("batch.size", 16384);
        props.put("linger.ms", 1);
        props.put("buffer.memory", 33554432);
        props.put("key.serializer",
        "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer",
        "org.apache.kafka.common.serialization.StringSerializer");

        // 2 构建拦截链
        List<String> interceptors = new ArrayList<>();
        interceptors.add("com.atguigu.kafka.interceptor.TimeInterceptor");
        interceptors.add("com.atguigu.kafka.interceptor.CounterInterceptor");
        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);
        String topic = "first";
        Producer<String, String> producer = new KafkaProducer<>(props);

        // 3 发送消息
        for (int i = 0; i < 10; i++) {
         ProducerRecord<String, String> record = new ProducerRecord<>(topic,
        "message" + i);
         producer.send(record);
        }

        // 4 一定要关闭 producer，这样才会调用 interceptor 的 close 方法
        producer.close();
	}
}
```
