---
layout: post
title: "Hadoop完全分布式运行模式"
date: 2019-02-20
description: "hadoop集群测试"
tag: 大数据
---  
## 环境、配置的准备工作
在VMware在克隆3个Centos6.10,开始做以下工作
### 关闭防火墙（Centos6.x）
```
service iptables stop    # 关闭防火墙
service iptables status  # 查看防火墙状态
chkconfig iptables off   # 关闭防火墙开启自启
```
### 设置静态IP
将网络适配器设置为NAT 即可自动分配静态IP
### 更改主机名称
```
# 查看当前主机名称
[root@hadoop101 Desktop]# hostname   
hadoop101

# 编辑/etc/sysconfig/network文件，将HOSTNAME设置为hadoop101：
[root@hadoop101 Desktop]# cat /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=hadoop101
NTPSERVERARGS=iburst
```
### 安装JDK，配置环境变量
这里为了统一，创建两个文件夹，一个放安装包，一个放安装文件，日后所有要安装的统一放这两个文件夹
```
[root@hadoop101 opt]# mkdir module
[root@hadoop101 opt]# mkdir software

# 查看创建
[root@hadoop101 opt]# ls
module  software

# 查看之间是否有安装过java软件
[root@hadoop101 opt]# rpm -qa | grep java
若有，既先卸载
[root@hadoop101 opt]# rpm -e 软件包

# 下好的安装包用xftp或者其他软件传输到/opt/software目录下
[root@hadoop101 software]# ls
jdk-8u231-linux-x64.tar.gz

# 解压jdk到 /opt/module目录下
[root@hadoop101 opt]# tar -zxvf jdk-8u231-linux-x64.tar.gz -C /opt/module/

# 配置jdk环境变量
[root@hadoop101 opt]# vim /etc/profile
在文件末尾添加jdk路径，保存退出
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_231
export PATH=$PATH:$JAVA_HOME/bin
# 让文件生效： source /etc/profile

# 进入所在目录/opt/module/jdk1.8.0_231，测试是否安装成功
[root@hadoop101 jdk1.8.0_231]# java -version
java version "1.8.0_231"
Java(TM) SE Runtime Environment (build 1.8.0_231-b11)
Java HotSpot(TM) 64-Bit Server VM (build 25.231-b11, mixed mode)
```
### 安装Hadoop
```
# 前面所有步骤同安装JDK
# 然后在/etc/profile文件中配置hadoop环境，加入文件末尾以下内容
# HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-2.7.7
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
# 记得让其生效：source /etc/profile
# 查看是否安装成功
[root@hadoop101 hadoop-2.7.7]# hadoop version
Hadoop 2.7.7
Subversion Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac
...
```
### 给所有集群节点安装以上环境
如果有几十个，几百个节点，一个一个节点安装的话，那显然不合理
#### 方法一（此方法可以push，也可以pull）：
scp 安全拷贝：实现服务器和服务器之间的数据拷贝
```
scp -r  要拷贝的文件路径/名称   目的用户@主机:目的路径/名称
如在hadoop101上，将hadoop101中/opt/module目录下的软件拷贝到hadoop102上的/opt/module
[root@hadoop101 opt]# scp -r /opt/module root@hadoop102:/opt/module
```
####方法二
xsync集群分发脚本：循环复制文件到所有节点的相同目录下
在/usr/local/bin目录下创建xsync文件（原因是在该目录下创建，脚本可以在全局使用）
```
[root@hadoop101 bin]# touch xsync
[root@hadoop101 bin]# vim xsync
```
在文件中加入：
```
#!/bin/bash
#1 获取输入参数个数，如果没有参数，直接退出
pcount=$#
if((pcount==0)); then
echo no args;
exit;
fi
#2 获取文件名称
p1=$1
fname=`basename $p1`
echo fname=$fname
#3 获取上级目录到绝对路径
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir
#4 获取当前用户名称
user=`whoami`
#5 循环
for((host=102; host<104; host++)); do
echo ------------------- hadoop$host --------------
rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
done
```
修改xsync的执行权限：
```
[root@hadoop101 bin]# chmod 777 xsync
```
### 实现各服务器之间无需登录密码通信
```
# 用 ll -a 可以看到home目录下有个.ssh文件夹
[root@hadoop101 ~]# ll -a
总用量 212
dr-xr-x---. 33 root root   4096 11月 20 12:42 .
drwx------.  2 root root   4096 11月 19 20:36 .ssh
drwxr-xr-x.  2 root root   4096 5月  13 2019 公共的
drwxr-xr-x.  2 root root   4096 5月  13 2019 模板
# 进入该目录，生成公钥和私钥
[root@hadoop101 .ssh]# ssh-keygen -t rsa
然后敲三次回车，就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）
# 将公钥拷贝到要免密登录的目标机器上
[root@hadoop101 .ssh]# ssh-copy-id hadoop101 (因为连自己也需要密码)
[root@hadoop101 .ssh]# ssh-copy-id hadoop102
[root@hadoop101 .ssh]# ssh-copy-id hadoop103
# 同理。hadoop102、hadoop103一样配置
```
## 集群正式开启工作
集群的部署规划

 name|hadoop101|hadoop102|hadoop103
 -|:-:|:-:|:-:
 HDFS|NameNode、DataNode|DataNode|SecondaryName、DataNode
 YARN|NodeManager|ResourceManager、NodeManager|NodeManager

 ### 核心配置文件
```
[root@hadoop101 hadoop]# pwd    # 当前的目录，配置文件都在这个目录中
/opt/module/hadoop-2.7.7/etc/hadoop
```
#### HDFS配置文件
```
[root@hadoop101 hadoop]# vim core-site.xml
在该文件中编写如下配置，注意是放在<configration></configration>中
<!-- 指定 HDFS 中 NameNode 的地址 -->
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://hadoop101:9000</value>
</property>
<!-- 指定 Hadoop 运行时产生文件的存储目录 -->
<property>
    <name>hadoop.tmp.dir</name>
    <value>/opt/module/hadoop-2.7.7/data/tmp</value>
</property>
```
配置hadoop-env.sh
```
[root@hadoop101 hadoop]# vim hadoop-env.sh
export JAVA_HOME=/opt/module/jdk1.8.0_231
```
配置hdfs-site.xml
```
<property>
    <name>dfs.replication</name>
    <value>3</value>
</property>
<!-- 指定 Hadoop 辅助名称节点主机配置 -->
<property>
    <name>dfs.namenode.secondary.http-address</name>
    <value>hadoop103:50090</value>
</property>
```
#### YARN配置文件
配置 yarn-env.sh
```
[root@hadoop101 hadoop]# vim yarn-env.sh
export JAVA_HOME=/opt/module/jdk1.8.0_231
```
配置 yarn-site.xml
```
[atguigu@hadoop101 hadoop]# vim yarn-site.xml
在该文件中增加如下配置
<!-- Reducer 获取数据的方式 -->
<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>
<!-- 指定 YARN 的 ResourceManager 的地址 -->
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>hadoop102</value>
```
MapReduce 配置文件
```
[root@hadoop101 hadoop]# vim mapred-env.sh
export JAVA_HOME=/opt/module/jdk1.8.0_231
```
配置 mapred-site.xml
```
[root@hadoop101 hadoop]# cp mapred-site.xml.template mapred-site.xml
[root@hadoop101 hadoop]# vim mapred-site.xml
<!-- 指定 MR 运行在 Yarn 上 -->
<property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
```
在hadoop101上配置完所欲配置文件后，通过集群分发脚本分发到hadoop102、hadoop103节点上
```
[root@hadoop101 etc]$ xsync /hadoop
4．在其他节点随便点开一个配置文件查看文件分发情况
[atguigu@hadoop103 hadoop]# cat /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml
```
### 集群单点启动
如果集群是第一次启动，需要格式化 NameNode
```
[root@hadoop101 hadoop-2.7.7]# hadoop namenode -format
# hadoop101启动NameNode
[root@hadoop101 hadoop-2.7.7]# hadoop-daemon.sh start namenode
[root@hadoop101 hadoop-2.7.7]# jps # 查看刚启动的
3482 jps
3461 NameNode
# hadoop101、hadoop102、hadoop103启动DataNode
[root@hadoop101 hadoop-2.7.7]# hadoop-daemon.sh start datanode
```
如果几十个或几百个节点呢？，显然这种方法不可取！
### 群起集群
#### 配置slaves文件，里面默认只有localhost
```
[root@hadoop102 hadoop]# vim slaves
在该文件中增加如下内容(注意不能有空格、空行)：
hadoop101
hadoop102
hadoop103
```
#### 启动集群
1、如果集群是第一次启动，需要格式化 NameNode
```
[root@hadoop101 hadoop-2.7.7]# bin/hdfs namenode -format
```
2、启动 HDFS
```
[root@hadoop101 hadoop-2.7.7]# sbin/start-dfs.sh
```
3、启动YARN
```
[root@hadoop102 hadoop-2.7.7]# sbin/start-yarn.sh
注意：NameNode 和 ResourceManger 如果不是同一台机器，不能在 NameNode 上启动 YARN，应该在 ResouceManager 所在的机器上启动 YARN。
```
4、Web端查看对应情况
HDFS：http://hadoop101:9000
SecondaryNameNode：http://hadoop103:50090/status.html

# 大功告成！
